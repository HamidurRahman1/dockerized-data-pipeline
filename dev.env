
# Path to local file system to be used in volumes. Currently, current working dir (project dir).
MOUNT_VOL=/Users/hamidurrahman/Downloads/GitHub/dockerized-data-pipeline


# Container names
DDP_AF_PG_METADB_NAME=ddp-airflow-pg-metadb
DDP_AF_PG_WEBSERVER_NAME=ddp-airflow-webserver
DDP_AF_PG_SCHEDULER_NAME=ddp-airflow-scheduler

DDP_REDIS_NAME=ddp-redis
DDP_CELERY_WORKER_1_NAME=ddp-celery-worker-n1
DDP_CELERY_FLOWER_NAME=ddp-celery-flower

DDP_PG_METADB_NAME=ddp-pg-metadb

DDP_REST_API_NAME=ddp-rest-api



# Timezone
TMZ=America/New_York


# Airflow postgres meta db variables.
AF_META_DB_USERNAME=airflow
AF_META_DB_PASS=pass
AF_META_DB=airflow

# DDP postgres meta db variables.
DDP_META_DB_USERNAME=ddp_user
DDP_META_DB_PASS=ddp_pass
DDP_META_DB=ddp_db


# Common airflow variables
AF_DB_URL=postgresql+psycopg2://${AF_META_DB_USERNAME}:${AF_META_DB_PASS}@${DDP_AF_PG_METADB_NAME}/${AF_META_DB}


# Airflow admin user
AF_ROLE=Admin
AF_USERNAME=admin
AF_PASS=admin
AF_FIRSTNAME=Hamidur
AF_LASTNAME=Rahman
AF_EMAIL=email@domain.com


# Redis and celery
CELERY_BROKER_URL=redis://${DDP_REDIS_NAME}:6379/0
CELERY_RESULT_BACKEND=db+postgresql://${AF_META_DB_USERNAME}:${AF_META_DB_PASS}@${DDP_AF_PG_METADB_NAME}/${AF_META_DB}


