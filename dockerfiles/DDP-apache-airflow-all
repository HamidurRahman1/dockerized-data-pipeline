
FROM apache/airflow:slim-2.7.2-python3.9

ENV TZ=America/New_York

RUN pip install apache-airflow-providers-postgres \
    && pip install redis \
    && pip install apache-airflow-providers-celery \
    && pip install --upgrade pip

USER root

ARG DB_URL
ARG DB_USER
ARG DB_PASS

ARG JAVA8_VERSION=8
ARG MAVEN_VERSION=3.8.4
ARG SPARK_VERSION=3.3.1
ARG HADOOP_SPARK_VERSION=3

ENV GROOVY_HOME=/opt/groovy
ENV JAVA_HOME=/opt/java8
ENV MAVEN_HOME=/opt/maven
ENV SPARK_HOME=/opt/spark

RUN apt-get update \
    && apt-get upgrade -y \
    && apt-get install -y \
        ca-certificates \
        locales \
        curl \
        wget \
        zip \
        unzip \
    && apt-get update

RUN wget -O - https://packages.adoptium.net/artifactory/api/gpg/key/public | sudo apt-key add - \
    && echo "deb https://packages.adoptium.net/artifactory/deb $(awk -F= '/^VERSION_CODENAME/{print$2}' /etc/os-release) main" | sudo tee /etc/apt/sources.list.d/adoptium.list \
    && apt-get update \
    && apt-get install temurin-${JAVA8_VERSION}-jdk -y \
    && ln -s /usr/lib/jvm/temurin-${JAVA8_VERSION}-jdk-amd64 $JAVA_HOME

# as of this development java PATH should be set before installing groovy otherwise groovy is going to install java11 and set it in env
ENV PATH $PATH:$JAVA_HOME/bin

RUN mkdir -p $MAVEN_HOME \
     && curl -fsSL -o /opt/apache-maven.tar.gz https://archive.apache.org/dist/maven/maven-3/${MAVEN_VERSION}/binaries/apache-maven-${MAVEN_VERSION}-bin.tar.gz \
     && tar -xzf /opt/apache-maven.tar.gz -C $MAVEN_HOME --strip-components=1 \
     && rm -f /opt/apache-maven.tar.gz

ENV PATH $PATH:$MAVEN_HOME/bin

RUN apt-get update && apt-get install -y groovy \
    && ln -s /usr/share/groovy $GROOVY_HOME

ENV PATH $PATH:$GROOVY_HOME/bin

RUN wget -q "https://archive.apache.org/dist/spark/spark-${SPARK_VERSION}/spark-${SPARK_VERSION}-bin-hadoop${HADOOP_SPARK_VERSION}.tgz" -O spark.tgz \
    && tar xzf spark.tgz -C /opt \
    && ln -s /opt/spark-${SPARK_VERSION}-bin-hadoop${HADOOP_SPARK_VERSION} $SPARK_HOME \
    && rm spark.tgz

ENV PATH $PATH:$SPARK_HOME/bin

RUN mkdir -p /app/ddp-backend/ /app/jars/ddp-hibernate /app/jars/ddp-rest /app/jars/ddp-spark/lib \
    && chmod 777 -R /app

COPY ../ddp-backend/ /app/ddp-backend

WORKDIR /app/ddp-backend

RUN mvn clean install -Plocal -U -DskipTests -Dddp.db.url=${DB_URL} -Dddp.db.user=${DB_USER} -Dddp.db.pass=${DB_PASS}

RUN apt-get update \
    && apt-get clean \
    && rm -rf /var/lib/apt/lists/* \
    && apt-get autoremove -y

USER airflow

WORKDIR /home/airflow

CMD ["/bin/bash"]


